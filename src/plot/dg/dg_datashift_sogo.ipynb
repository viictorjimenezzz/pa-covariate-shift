{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pyrootutils\n",
    "\n",
    "notebook_path = Path(os.path.abspath(\"\"))\n",
    "pyrootutils.setup_root(notebook_path, indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "DIRNAME = r\"/cluster/home/vjimenez/adv_pa_new/results/dg/datashift\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot.dg import *\n",
    "from src.plot.dg._retrieve import *\n",
    "from src.plot.dg._plot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET MODEL SELECTION TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionary(dataset_name, run_names: list, datashift: bool = True):\n",
    "    dirname = r\"/cluster/home/vjimenez/adv_pa_new/results/dg/datashift\"\n",
    "\n",
    "    data_dict_list = []\n",
    "    for run_name in tqdm(run_names, desc=\"Run: \"):\n",
    "        fname = osp.join(osp.join(dirname, dataset_name), f\"test_{run_name}.pkl\")\n",
    "        with open(fname, 'rb') as file:\n",
    "            data_dict = pickle.load(file) \n",
    "        data_dict_list.append(data_dict)\n",
    "\n",
    "    merged_dict = defaultdict(list)\n",
    "    for d in data_dict_list:\n",
    "        for key, value in d.items():\n",
    "            merged_dict[key].extend(value)\n",
    "\n",
    "    return merged_dict\n",
    "\n",
    "def get_multiple_dict(dataset_names, run_names, datashift: bool = True):\n",
    "    data_dict_list_2 = []\n",
    "    for dataset_name in dataset_names:\n",
    "        data_dict_list_2.append(\n",
    "            get_dictionary(dataset_name, run_names, datashift)\n",
    "        )\n",
    "\n",
    "    merged_dict = defaultdict(list)\n",
    "    for d in data_dict_list_2:\n",
    "        for key, value in d.items():\n",
    "            merged_dict[key].extend(value)\n",
    "\n",
    "    return pd.DataFrame(merged_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = get_multiple_dict(\n",
    "        dataset_names=[\"CGO_1_hue\"],\n",
    "        run_names=[\n",
    "            \"erm\",\n",
    "        ],\n",
    "        datashift = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EN MASSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/cluster/home/vjimenez/adv_pa_new/results/dg/datashift/CGO_1_pos/test_irm.pkl\", 'rb') as file:\n",
    "    data_dict = pickle.load(file) \n",
    "\n",
    "df = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"acc\"\n",
    "selection_metric = \"AFR_pred\"\n",
    "\n",
    "df_sel = df.loc[\n",
    "    (df[\"sr\"] == 1.0) & (df[\"env1\"] == \"1\"),\n",
    "    [\n",
    "        \"sr\",\n",
    "        \"selection_metric\",\n",
    "        \"env1\",\n",
    "        metric,\n",
    "     ]\n",
    "]\n",
    "\n",
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel[df_sel[\"selection_metric\"] == \"logPA\"][\"acc\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DICT = {\n",
    "    \"ZSO_hue_3\": \"ZSO\",\n",
    "    \"ZGO_hue_3\": \"ZGO\",\n",
    "    \"CGO_1_hue\": \"1-CGO\",\n",
    "    \"CGO_2_hue\": \"2-CGO\",\n",
    "    \"CGO_3_hue\": \"3-CGO\",\n",
    "    \"ZSO_pos_3\": \"ZSO\",\n",
    "    \"ZGO_pos_3\": \"ZGO\",\n",
    "    \"CGO_1_pos\": \"1-CGO\",\n",
    "    \"CGO_2_pos\": \"2-CGO\",\n",
    "    \"CGO_3_pos\": \"3-CGO\"\n",
    "}\n",
    "\n",
    "FACTOR_DICT = {\n",
    "    \"pos\": r\"\\texttt{position}\",\n",
    "    \"hue\": r\"\\texttt{hue}\"\n",
    "}\n",
    "\n",
    "MODEL_NAMES = {\n",
    "    \"erm\": r\"{\\color{tab:blue} \\textbf{ERM}}\",\n",
    "    \"irm\": r\"{\\color{tab:orange} \\textbf{IRM}}\",\n",
    "    \"lisa\": r\"{\\color{tab:green} \\textbf{LISA}}\"\n",
    "}\n",
    "\n",
    "\n",
    "def dataset_name_parser(ds_name: str):\n",
    "    return f\"{DATASET_DICT[ds_name]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(\n",
    "        model_name_list: list[str],\n",
    "        ds_name_list: list[str],\n",
    "        lr: float,\n",
    "        main_factor: str,\n",
    "    ):\n",
    "    dataset_names_parsed = [DATASET_DICT[ds_name] for ds_name in ds_name_list]\n",
    "    # model_names_parsed = [MODEL_NAMES[model_name.split(\"_\")[0]] for model_name in model_name_list]\n",
    "    model_names_parsed = model_name_list\n",
    "    \n",
    "    # Start building the LaTeX table\n",
    "    latex_code = \"\\\\begin{table}[H]\\n\\\\centering\\n\\\\setlength{\\\\tabcolsep}{2.5pt}\\n\\\\resizebox{\\\\textwidth}{!}{%\\n\\\\begin{tabular}{l|ccc|ccc|ccc|ccc|ccc}\\n\"\n",
    "\n",
    "    # Header for shift values\n",
    "    # shift_text = lambda shift: f\"Test \\#{shift}\"\n",
    "    shift_text = lambda shift: f\"Acc. Test {shift}\"\n",
    "    latex_code += \"\\\\multirow{3}{*}{} & \" + \" & \".join(\n",
    "        [\n",
    "        f\"\\\\multicolumn{{3}}{{c|}}{{\\\\textbf{{{shift_text(shift)}}}}}\" if shift < 5 else f\"\\\\multicolumn{{3}}{{c}}{{\\\\textbf{{{shift_text(shift)}}}}}\"\n",
    "        for shift in range(1, 6)\n",
    "    ]\n",
    "    ) + \" \\\\\\\\\\n\"\n",
    "\n",
    "    eps = 1e-4\n",
    "    \n",
    "    # Iterate over each model\n",
    "    for imodel, (model, model_parsed) in enumerate(zip(model_name_list, model_names_parsed)):\n",
    "        # Header for metrics (Acc., PA)\n",
    "        latex_code += f\"\\\\textbf{{{model_parsed}}} & \" + \" & \".join(\n",
    "            # [r\"\\textbf{Acc.} & \\textbf{PA}\" for _ in range(6)]\n",
    "            [r\"Acc. & AFR$_\\text{P}$ & PA\" for _ in range(1, 6)]\n",
    "        ) + \" \\\\\\\\\\n\"\n",
    "        latex_code += \"\\\\midrule\\n\"\n",
    "\n",
    "        # Iterate over each dataset\n",
    "        for idataset, (dataset, dataset_parsed) in enumerate(zip(ds_name_list, dataset_names_parsed)):\n",
    "            latex_code += f\"{dataset_parsed}\"\n",
    "            # latex_code += f\"\\\\textbf{{{dataset_parsed}}}\"\n",
    "\n",
    "            try:\n",
    "                with open(rf\"/cluster/home/vjimenez/adv_pa_new/results/dg/datashift/{dataset}/test_{model}.pkl\", 'rb') as file:\n",
    "                    df = pd.DataFrame((pickle.load(file)))\n",
    "            except:\n",
    "                continue\n",
    "      \n",
    "            for shift in range(1, 6):\n",
    "                # Filter the DataFrame for the current dataset, model, and shift\n",
    "                row = df[(df['env1'] == str(shift)) & (df[\"sr\"] == 1.0)]\n",
    "                if not row.empty:                    \n",
    "                    # Extract the metric values for the current dataset, model, and shift\n",
    "                    acc = 100.0*row[row[\"selection_metric\"] == \"acc\"][\"acc\"].values[0]\n",
    "                    beta = 100.0*row[row[\"selection_metric\"] == \"acc\"][\"beta\"].values[0]\n",
    "\n",
    "                    pa = 100.0*row[row[\"selection_metric\"] == \"logPA\"][\"acc\"].values[0]\n",
    "                    afr = 100.0*row[row[\"selection_metric\"] == \"AFR_pred\"][\"acc\"].values[0]\n",
    "\n",
    "\n",
    "                    acc_str, pa_str, afr_str = f\"{acc:.1f}\", f\"{pa:.1f}\", f\"{afr:.1f}\"\n",
    "                    str_metrics = [acc_str, afr_str, pa_str]\n",
    "                    float_metrics = [float(val) for val in str_metrics]\n",
    "                    max_val = max(float_metrics)\n",
    "                    if abs(float_metrics[2] - max_val) < eps:\n",
    "                        pa_str = f\"{{\\\\textbf{{{pa_str}}}}}\"\n",
    "                    elif abs(float_metrics[0] - max_val) < eps:\n",
    "                        acc_str = f\"{{\\\\textbf{{{acc_str}}}}}\"\n",
    "                    else:\n",
    "                        afr_str = f\"{{\\\\textbf{{{afr_str}}}}}\"\n",
    "\n",
    "                    pa_str = \"_________\" + str(beta) + \"_________\"\n",
    "\n",
    "\n",
    "                    latex_code += f\" & {acc_str} & {afr_str} & {pa_str}\"\n",
    "                else:\n",
    "                    latex_code += \" & - & - & -\"  # Placeholder if there's no data\n",
    "\n",
    "\n",
    "                break\n",
    "            \n",
    "            latex_code += \" \\\\\\\\\\n\"\n",
    "\n",
    "        if imodel < len(model_name_list)-1:\n",
    "            latex_code += \"\\\\midrule\\n\\\\addlinespace\\n\\\\addlinespace\\n\"\n",
    "    \n",
    "    latex_code += \"\\\\bottomrule\\n\\\\end{tabular}%\\n}\\n\"\n",
    "\n",
    "    # Add caption with significant improvement information\n",
    "    caption_text = f\"REMOVE-lr={lr}-mf={main_factor}REMOVE Test performance on increasingly shifted datasets for models selected during ERM and IRM procedures. Different validation datasets are used, and the selection capabilities of PA and validation accuracy are compared.\"\n",
    "    latex_code += f\"\\\\caption{{{caption_text}}}\\n\\\\label{{tab:label}}\\n\\\\end\" + \"{\" + \"table}\"\n",
    "    \n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\setlength{\\tabcolsep}{2.5pt}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{l|ccc|ccc|ccc|ccc|ccc}\n",
      "\\multirow{3}{*}{} & \\multicolumn{3}{c|}{\\textbf{Acc. Test 1}} & \\multicolumn{3}{c|}{\\textbf{Acc. Test 2}} & \\multicolumn{3}{c|}{\\textbf{Acc. Test 3}} & \\multicolumn{3}{c|}{\\textbf{Acc. Test 4}} & \\multicolumn{3}{c}{\\textbf{Acc. Test 5}} \\\\\n",
      "\\textbf{irm_adam_001} & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA \\\\\n",
      "\\midrule\n",
      "ZGO & 50.1 & 56.0 & _________0.0_________ \\\\\n",
      "1-CGO & 63.0 & 64.0 & _________0.0_________ \\\\\n",
      "2-CGO & 69.0 & {\\textbf{82.4}} & _________0.0_________ \\\\\n",
      "3-CGO & 79.5 & 91.1 & _________0.0_________ \\\\\n",
      "ZSO & 99.4 & 99.5 & _________116.32434129714966_________ \\\\\n",
      "\\midrule\n",
      "\\addlinespace\n",
      "\\addlinespace\n",
      "\\textbf{irm_0001} & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA \\\\\n",
      "\\midrule\n",
      "ZGO & 51.9 & 52.8 & _________0.0_________ \\\\\n",
      "1-CGO & 63.1 & {\\textbf{67.0}} & _________0.0_________ \\\\\n",
      "2-CGO & 73.7 & {\\textbf{80.8}} & _________17.3472061753273_________ \\\\\n",
      "3-CGO & 76.5 & 83.5 & _________0.0_________ \\\\\n",
      "ZSO & {\\textbf{99.4}} & 99.4 & _________154.60633039474487_________ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}%\n",
      "}\n",
      "\\caption{REMOVE-lr=0.001-mf=hueREMOVE Test performance on increasingly shifted datasets for models selected during ERM and IRM procedures. Different validation datasets are used, and the selection capabilities of PA and validation accuracy are compared.}\n",
      "\\label{tab:label}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "latex_table = generate_latex_table(\n",
    "        model_name_list = ['irm_adam_001', 'irm_0001'],\n",
    "        ds_name_list = ['ZGO_hue_3', 'CGO_1_hue','CGO_2_hue','CGO_3_hue','ZSO_hue_3'],\n",
    "        # ds_name_list=['ZGO_pos_3','CGO_1_pos','CGO_2_pos','CGO_3_pos','ZSO_pos_3'],\n",
    "        lr = 0.001,\n",
    "        main_factor = 'hue',\n",
    ")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLES OF SURPLUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(\n",
    "        model_name_list: list[str],\n",
    "        ds_name_list: list[str],\n",
    "        lr: float,\n",
    "        main_factor: str,\n",
    "    ):\n",
    "    dataset_names_parsed = [DATASET_DICT[ds_name] for ds_name in ds_name_list]\n",
    "    model_names_parsed = [MODEL_NAMES[model_name.split(\"_\")[0]] for model_name in model_name_list]\n",
    "    \n",
    "    # Start building the LaTeX table\n",
    "    latex_code = \"\\\\begin{table}[H]\\n\\\\centering\\n\\\\resizebox{\\\\textwidth}{!}{%\\n\\\\begin{tabular}{l|cl|cl|cl|cl|cl}\\n\"\n",
    "\n",
    "    # Header for shift values\n",
    "    # shift_text = lambda shift: f\"Test \\#{shift}\"\n",
    "    shift_text = lambda shift: f\"Test {shift}\"\n",
    "    latex_code += \"\\\\multirow{2}{*}{} & \" + \" & \".join(\n",
    "        [\n",
    "        f\"\\\\multicolumn{{2}}{{c|}}{{\\\\textbf{{{shift_text(shift)}}}}}\" if shift < 5 else f\"\\\\multicolumn{{2}}{{c}}{{\\\\textbf{{{shift_text(shift)}}}}}\"\n",
    "        for shift in range(1, 6)\n",
    "    ]\n",
    "    ) + \" \\\\\\\\\\n\"\n",
    "\n",
    "    eps = 1e-4\n",
    "    \n",
    "    # Iterate over each model\n",
    "    for imodel, (model, model_parsed) in enumerate(zip(model_name_list, model_names_parsed)):\n",
    "        # Header for metrics (Acc., PA)\n",
    "        latex_code += f\"\\\\textbf{{{model_parsed}}} & \" + \" & \".join(\n",
    "            # [r\"\\textbf{Acc.} & \\textbf{PA}\" for _ in range(6)]\n",
    "            [r\"Acc. & $\\Delta$Acc.\" for _ in range(1, 6)]\n",
    "        ) + \" \\\\\\\\\\n\"\n",
    "        latex_code += \"\\\\midrule\\n\"\n",
    "\n",
    "        # Iterate over each dataset\n",
    "        for idataset, (dataset, dataset_parsed) in enumerate(zip(ds_name_list, dataset_names_parsed)):\n",
    "            latex_code += f\"{dataset_parsed}\"\n",
    "            # latex_code += f\"\\\\textbf{{{dataset_parsed}}}\"\n",
    "\n",
    "            try:\n",
    "                with open(rf\"/cluster/home/vjimenez/adv_pa_new/results/dg/datashift/{dataset}/test_{model}.pkl\", 'rb') as file:\n",
    "                    df = pd.DataFrame((pickle.load(file)))\n",
    "            except:\n",
    "                continue\n",
    "      \n",
    "            for shift in range(1, 6):\n",
    "                # Filter the DataFrame for the current dataset, model, and shift\n",
    "                row = df[(df['env1'] == str(shift)) & (df[\"sr\"] == 1.0)]\n",
    "                if not row.empty:\n",
    "                    \n",
    "                    # Extract the metric values for the current dataset, model, and shift\n",
    "                    acc = 100.0*row[row[\"selection_metric\"] == \"acc\"][\"acc\"].values[0]\n",
    "                    pa = 100.0*row[row[\"selection_metric\"] == \"logPA\"][\"acc\"].values[0] - 100.0*row[row[\"selection_metric\"] == \"acc\"][\"acc\"].values[0]\n",
    "\n",
    "                    acc_str = f\"{acc:.1f}\"\n",
    "                    if float(f\"{pa:.1f}\") > 0:\n",
    "                        pa_str_in = f\"\\Plus {abs(pa):.1f}\"\n",
    "                        pa_str = f\"{{\\\\color{{tab:green}}  \\\\textbf{{{pa_str_in}}}}}\"\n",
    "                    elif float(f\"{pa:.1f}\") < 0:\n",
    "                        pa_str_in = f\"\\Minus {abs(pa):.1f}\"\n",
    "                        pa_str = f\"{{\\\\color{{tab:red}} \\\\textbf{{{pa_str_in}}}}}\"\n",
    "                    else:\n",
    "                        pa_str = r\"\\PlusMinus 0.01\" #\"0.0\"\n",
    "\n",
    "\n",
    "                    latex_code += f\" & {acc_str} & {pa_str}\"\n",
    "                else:\n",
    "                    latex_code += \" & - & -\"  # Placeholder if there's no data\n",
    "            latex_code += \" \\\\\\\\\\n\"\n",
    "\n",
    "\n",
    "        if imodel < len(model_name_list)-1:\n",
    "            latex_code += \"\\\\midrule\\n\\\\addlinespace\\n\\\\addlinespace\\n\"\n",
    "    \n",
    "    latex_code += \"\\\\bottomrule\\n\\\\end{tabular}%\\n}\\n\"\n",
    "\n",
    "    # Add caption with significant improvement information\n",
    "    caption_text = f\"REMOVE-lr={lr}-mf={main_factor}REMOVE\"\n",
    "    latex_code += f\"\\\\caption{{{caption_text}}}\\n\\\\label{{tab:label}}\\n\\\\end\" + \"{\" + \"table}\"\n",
    "    \n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = generate_latex_table(\n",
    "        model_name_list = ['irm_0001', 'irm_adam_001'],\n",
    "        ds_name_list = ['ZGO_hue_3', 'CGO_1_hue','CGO_2_hue','CGO_3_hue','ZSO_hue_3'],\n",
    "        # ds_name_list=['ZSO_pos_3','CGO_1_pos','CGO_2_pos','CGO_3_pos','ZGO_pos_3'],\n",
    "        lr = 0.001,\n",
    "        main_factor = 'hue',\n",
    ")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_pa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
