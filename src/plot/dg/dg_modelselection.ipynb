{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pyrootutils\n",
    "\n",
    "notebook_path = Path(os.path.abspath(\"\"))\n",
    "pyrootutils.setup_root(notebook_path, indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "DIRNAME = r\"/cluster/home/vjimenez/adv_pa_new/results/dg/modelselection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot.dg import *\n",
    "from src.plot.dg._retrieve import *\n",
    "from src.plot.dg._plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project = \"DiagVib-6 OOD Model Selection\"\n",
    "# for dataset_name in ['pos_maxmixval']:\n",
    "#     for mod in [\"erm\", \"irm\"]:\n",
    "#         for opt in [\"adam\"]:\n",
    "#             for lr in [\"0.001\"]:\n",
    "#                 try:\n",
    "#                     data_dict = get_dictionary(dataset_name, [f\"mod={mod}_opt={opt}_lr={lr}\"], datashift=False)\n",
    "#                 except:\n",
    "#                     print(f\"No data found for this configuration: dataset_name={dataset_name}, mod={mod}, opt={opt}, lr={lr}\")\n",
    "\n",
    "ds_hue = ['hue_mixval','hue_maxmixval','hue_oodval']\n",
    "ds_pos = ['pos_zero','pos_idval','pos_mixval', 'pos_oodval']\n",
    "ds_hue_npair = ['hue_zero_npair','hue_idval_npair','hue_mixval_npair','hue_maxmixval_npair','hue_oodval_npair']\n",
    "ds_pos_npair = ['pos_zero_npair','pos_idval_npair','pos_mixval_npair','pos_maxmixval_npair','pos_oodval_npair']\n",
    "\n",
    "project = \"DiagVib-6 OOD Model Selection\"\n",
    "for dataset_name in ds_hue + ds_pos + ds_hue_npair + ds_pos_npair:\n",
    "    for lr in [\"0.0001\", \"0.0005\"]:\n",
    "        try:\n",
    "            data_dict = get_dictionary(dataset_name, [f\"mod=lisa_ppred=0.5_opt=adam_lr={lr}\"], datashift=False)\n",
    "        except:\n",
    "            print(f\"No data found for this configuration: dataset_name={dataset_name}, mod=lisa_ppred=0.5, opt=adam, lr={lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "def plot_variable_vs_run(\n",
    "        data: dict,\n",
    "        run_names: list,\n",
    "        metrics: list,\n",
    "        hue_attribute: str,\n",
    "        hue_dict: dict,\n",
    "        ylabel: str,\n",
    "        legend_labels: list,\n",
    "        title: str,\n",
    "        savedir: str,\n",
    "        yscale: Optional[bool] = \"symlog\",\n",
    "        legend: Optional[bool] = True,\n",
    "        legend_loc: Optional[str] = \"best\",\n",
    "        save: Optional[bool] = False,\n",
    "        version_appendix: Optional[str] = \"\"\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            data (dict): Dictionary with all the data for the desired runs.\n",
    "            metric (str): Name of the metric to plot.\n",
    "            selection_metric (str): Name of the metric that guides the selection of the `metric` values to plot.\n",
    "            selection_criterion (str): Criterion of the `selection_metric`. Accepts \"min\", \"max\", \"first\" and \"last\".\n",
    "            selection_environment (Optional[int]): Environment to implement the selection criterion. If None, it will be implemented\n",
    "                for each environment separately.\n",
    "    \"\"\"\n",
    "    # Number of runs:\n",
    "    \n",
    "    run_attributes = [extract_names(name) for name in run_names] #(model, opt, lr)\n",
    "\n",
    "    name_datasets = set(data[\"dataset\"])\n",
    "    num_datasets = len(name_datasets)\n",
    "\n",
    "    # Get the font\n",
    "    fontname = \"DejaVu Serif\"\n",
    "    _ = fm.findfont(fm.FontProperties(family=fontname))\n",
    "\n",
    "    # Subset of the dictionary:\n",
    "    dict_to_iter = {\n",
    "        \"dataset\": data[\"dataset\"],\n",
    "        \"model\": [attrs[0] for attrs in run_attributes]*num_datasets,\n",
    "        \"optimizer\": [attrs[1] for attrs in run_attributes]*num_datasets,\n",
    "        \"lr\": [float(attrs[2]) for attrs in run_attributes]*num_datasets,\n",
    "    }    \n",
    "\n",
    "    df_list = []\n",
    "    for irun in range(len(data[\"dataset\"])):\n",
    "        dict_to_plot = {\n",
    "            \"epochs\": np.arange(1, 101)\n",
    "        }\n",
    "        dict_to_plot.update({\n",
    "            key: np.full(100, values[irun])\n",
    "            for key, values in dict_to_iter.items()\n",
    "        })\n",
    "        dict_to_plot.update({\n",
    "            metric: data[metric][irun]\n",
    "            for metric in metrics\n",
    "        })\n",
    "        df_list.append(pd.DataFrame(dict_to_plot))\n",
    "    \n",
    "    level_set = pd.concat(df_list)\n",
    "    \n",
    "    # Create a line plot\n",
    "    plt.close('all')\n",
    "    _, ax = plt.subplots(figsize=(2 * 3.861, 2 * 2.7291))\n",
    "    sns.set(font_scale=1.9)\n",
    "    plt.rcParams[\"font.family\"] = \"serif\"\n",
    "    plt.rcParams[\"font.serif\"] = fontname\n",
    "    sns.set_style(\"ticks\")\n",
    "\n",
    "\n",
    "    for metric in metrics:\n",
    "        sns.lineplot(\n",
    "            data=level_set,\n",
    "            ax=ax,\n",
    "            x=\"epochs\",\n",
    "            y=metric,\n",
    "            hue=hue_attribute,\n",
    "            style=hue_attribute,\n",
    "            palette=hue_dict,\n",
    "            dashes=False, #[(2,2)] if metric == metrics[0] else False, #dash_styles.get(metric, False),\n",
    "            marker=None,\n",
    "            linewidth=3,\n",
    "            legend=legend\n",
    "        )\n",
    "\n",
    "    # ax.minorticks_on()\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "    ax.set_xticks([1] + [i for i in range(10,101,10)])\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", direction=\"in\")\n",
    "    xticks_font = fm.FontProperties(family=fontname)\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_fontproperties(xticks_font)\n",
    "\n",
    "    ax.grid(linestyle=\"--\")\n",
    "\n",
    "    # ax.set_ylim(min(level_set[metric])*2, 0.5)\n",
    "        \n",
    "    # posdiff = -(10**np.log10(abs(max(level_set[metric]))))/2\n",
    "    # ax.set_ylim(min(level_set[metric])*2, posdiff)\n",
    "    ax.set_xlabel(\"Epochs\", fontname=fontname)\n",
    "    # r\"$10^{-4} \\times $ PA\"\n",
    "    ax.set_ylabel(ylabel, fontname=fontname)\n",
    "    ax.set_yscale(yscale) \n",
    "    \n",
    "    # Legend\n",
    "    if legend == True:\n",
    "        handles, _ = ax.get_legend_handles_labels()\n",
    "\n",
    "        # FOR TRAIN AND VAL METRICS:\n",
    "        # legend_labels = [\"Training\", \"Validation\"] + legend_labels\n",
    "        \n",
    "        # for handle in handles[:2]:\n",
    "        #     handle.set_color(\"black\")\n",
    "        # handles[1].set_linestyle(\"-\")\n",
    "        \n",
    "            \n",
    "        legend_properties = {\n",
    "            \"family\": fontname,\n",
    "            'size': 18,\n",
    "        }  \n",
    "        ax.legend(\n",
    "            handles,\n",
    "            legend_labels,\n",
    "            loc=legend_loc,\n",
    "            # loc=\"lower left\",\n",
    "            # fontsize=12,\n",
    "            handlelength=0.5,\n",
    "            prop=legend_properties\n",
    "        )\n",
    "\n",
    "    ax.set_title(title, fontname=fontname)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(savedir)\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_names = [f\"mod=irm_opt=adam_lr=0.001\"]\n",
    "ds_name = \"pos_maxmixval\"\n",
    "data_dict = get_multiple_dict(\n",
    "    [ds_name],\n",
    "    run_names,\n",
    "    datashift=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_metrics = [\"acc\", \"loss\", \"specificity\", \"sensitivity\", \"precision\"]\n",
    "for met in trainval_metrics: \n",
    "    if met != \"loss\":\n",
    "        continue\n",
    "    \n",
    "    legend = False\n",
    "    if met == \"loss\":\n",
    "        legend = True\n",
    "\n",
    "    mettitle = met.capitalize()\n",
    "    if met == \"acc\":\n",
    "        mettitle = \"Accuracy\"\n",
    "\n",
    "    plot_variable_vs_run(\n",
    "        data=data_dict,\n",
    "        run_names=run_names,\n",
    "        metrics=[f\"train/{met}\", f\"val/{met}\"],\n",
    "        hue_attribute=\"lr\",\n",
    "        hue_dict={\n",
    "            0.0001: \"tab:cyan\",\n",
    "            0.001: \"tab:pink\"\n",
    "        },\n",
    "        title=f\"{mettitle}\",\n",
    "        legend_labels=[\"0.0001\", \"0.001\"],\n",
    "        ylabel=\"\",\n",
    "        # title=f\"{mod.upper()}\",\n",
    "        savedir=os.path.join(DIRNAME, rf\"{ds_name}/{mod}_lr_{met}.png\"),\n",
    "        yscale=\"linear\",\n",
    "        legend=legend,\n",
    "        save=False,\n",
    "        version_appendix=\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = \"irm\"\n",
    "run_names = [f\"mod={mod}_opt=sgd_lr=0.001\", f\"mod={mod}_opt=sgd_lr=0.0001\"]\n",
    "ds_name = \"hue_idval_17\"\n",
    "data_dict = get_multiple_dict(\n",
    "    [ds_name],\n",
    "    run_names,\n",
    "    datashift=False\n",
    ")\n",
    "\n",
    "met = \"beta\"\n",
    "plot_variable_vs_run(\n",
    "        data=data_dict,\n",
    "        run_names=run_names,\n",
    "        metrics=[f\"PA(0,1)/{met}\"],\n",
    "        hue_attribute=\"lr\",\n",
    "        hue_dict={\n",
    "            0.0001: \"tab:cyan\",\n",
    "            0.001: \"tab:pink\"\n",
    "        },\n",
    "        ylabel=r\"$\\beta$\",\n",
    "        legend_labels=[\"0.0001\", \"0.001\"],\n",
    "        legend_loc=\"best\",\n",
    "        title=f\"{mod.upper()}\",\n",
    "        savedir=os.path.join(DIRNAME, rf\"{ds_name}/{mod}_lr_{met}.png\"),\n",
    "        yscale=\"linear\",\n",
    "        legend=False,\n",
    "        save=True,\n",
    "        version_appendix=\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_cov_det(data_dict, epoch, run_index):\n",
    "    cov_matrix = np.vstack([data_dict[f\"COV_{epoch}\"][run_index*2], data_dict[f\"COV_{epoch}\"][run_index*2 + 1]])\n",
    "    return np.linalg.det(cov_matrix)\n",
    "\n",
    "epoch_filter = np.asarray([0, 10, 20, 30, 40, 49])\n",
    "cov_data = [_get_cov_det(data_dict, epoch, r) for epoch in epoch_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE OF RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "def _get_table_of_results(\n",
    "        model_list: list[str],\n",
    "        main_factor: str,\n",
    "        n_pair: bool,\n",
    "        optimizer: str, \n",
    "        lr: float\n",
    "    ):\n",
    "\n",
    "    df_list = []\n",
    "    for mod in model_list:\n",
    "        # 1. LOAD THE APPROPIATE DATA:\n",
    "\n",
    "        # The name of the runs we want to compare\n",
    "        # run_names = [\n",
    "        #     f\"mod={mod}_opt={optimizer}_lr={lr}\"\n",
    "        # ]\n",
    "\n",
    "        run_names = [\n",
    "            f\"mod=lisa_ppred=0.5_opt={optimizer}_lr={lr}\"\n",
    "        ]\n",
    "\n",
    "        # The datasets for which we want to compare them:\n",
    "        # val_names = [\"zero\", \"idval\", \"mixval\", \"maxmixval\", \"oodval\"]\n",
    "        if n_pair == True:\n",
    "            val_names = [\"zero_npair\", \"idval_npair\", \"mixval_npair\", \"maxmixval_npair\", \"oodval_npair\"]\n",
    "        else:\n",
    "            val_names = [\"zero\", \"idval\", \"mixval\", \"maxmixval\", \"oodval\"]\n",
    "\n",
    "        ds_names = [\n",
    "            main_factor + '_' + val_name\n",
    "            for val_name in val_names\n",
    "        ]\n",
    "\n",
    "        # Obtain the whole dataset:\n",
    "        data_dict_list = []\n",
    "        for ds_name in ds_names:\n",
    "            for run_name in run_names:\n",
    "                try:\n",
    "                    # data_dict_list.append(\n",
    "                    #     get_dictionary(ds_name, [run_name], datashift=False) # this is model selection\n",
    "                    # )\n",
    "\n",
    "                    with open(rf\"/cluster/home/vjimenez/adv_pa_new/results/dg/modelselection/{ds_name}/mod=lisa_ppred=0.5_opt={optimizer}_lr={lr}.pkl\", 'rb') as f:\n",
    "                        data_dict_list.append(\n",
    "                            pickle.load(f)\n",
    "                        )\n",
    "\n",
    "                except:\n",
    "                    print(f\"No dataset for this configuration: {ds_name} + {run_name}\")\n",
    "\n",
    "        data_dict = defaultdict(list)\n",
    "        for d in data_dict_list:\n",
    "            for key, value in d.items():\n",
    "                data_dict[key].extend(value)\n",
    "\n",
    "\n",
    "        # 2. RETRIEVE ONLY USEFUL INFORMATION.\n",
    "        num_datasets = len(data_dict['seed'])\n",
    "        list_selection_metrics = [\"val/acc\", \"PA(0,1)/AFR_pred\", \"PA(0,1)/logPA\"]\n",
    "\n",
    "        selection_dictionary_table = {}\n",
    "        for idat, dat in enumerate(data_dict['dataset']):\n",
    "            selection_dictionary_table[dat] = {\n",
    "                \"epoch\": [data_dict[metric][idat].argmax() for metric in list_selection_metrics],\n",
    "                \"value\": [data_dict[metric][idat].max() for metric in list_selection_metrics],\n",
    "            }\n",
    "            selection_dictionary_table[dat].update({\n",
    "                f\"acc@{e}\": [\n",
    "                    data_dict[f'oracle/acc_{e}'][idat][selection_dictionary_table[dat][\"epoch\"][imet]]\n",
    "                    for imet in range(len(list_selection_metrics))\n",
    "                ]\n",
    "                for e in range(0, 6)\n",
    "            })\n",
    "\n",
    "        # 3. CONVERT TO PANDAS DF:\n",
    "        columns = ['shift', 'metric'] + list(selection_dictionary_table.keys())\n",
    "        rows = []\n",
    "        # Iterate through shifts (acc@0 to acc@5)\n",
    "        for shift in range(6):\n",
    "            shift_key = f'acc@{shift}'\n",
    "            # Iterate through metrics\n",
    "            for idx, metric in enumerate(['acc', 'afrp', 'pa']):\n",
    "                row = [shift, metric]\n",
    "                for key in selection_dictionary_table:\n",
    "                    # First value for 'acc', difference for 'afrp' and 'pa'\n",
    "                    base_value = selection_dictionary_table[key][shift_key][0]\n",
    "                    if metric == 'acc':\n",
    "                        value = base_value\n",
    "                    elif metric == 'afrp':\n",
    "                        # value = selection_dictionary_table[key][shift_key][1] - base_value\n",
    "                        value = selection_dictionary_table[key][shift_key][1]\n",
    "                    elif metric == 'pa':\n",
    "                        # value = selection_dictionary_table[key][shift_key][2] - base_value\n",
    "                        value = selection_dictionary_table[key][shift_key][2]\n",
    "                    row.append(value)\n",
    "                rows.append(row)\n",
    "\n",
    "        # Convert rows into a DataFrame\n",
    "        df = pd.DataFrame(rows, columns=columns)\n",
    "        df['model'] = mod\n",
    "        df_list.append(df)\n",
    "\n",
    "    return pd.concat(df_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add model selection keys based on the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DICT = {\n",
    "    \"zero\": \"SD\",\n",
    "    \"idval\": \"ID\",\n",
    "    \"mixval\": \"1F-MD\",\n",
    "    \"maxmixval\": \"5F-MD\",\n",
    "    \"oodval\": \"OOD\"\n",
    "}\n",
    "\n",
    "FACTOR_DICT = {\n",
    "    \"pos\": r\"\\texttt{position}\",\n",
    "    \"hue\": r\"\\texttt{hue}\"\n",
    "}\n",
    "\n",
    "MODEL_NAMES = {\n",
    "    \"erm\": r\"{\\color{tab:blue} \\textbf{ERM}}\",\n",
    "    \"irm\": r\"{\\color{tab:orange} \\textbf{IRM}}\",\n",
    "    \"lisa_ppred=0.5\": r\"{\\color{tab:green} \\textbf{LISA}}\"\n",
    "}\n",
    "\n",
    "\n",
    "def dataset_name_parser(ds_name: str):\n",
    "    list_name = ds_name.split(\"_\")\n",
    "    return f\"{DATASET_DICT[list_name[1]]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(df, optimizer: str, lr: float, main_factor: str, n_pair: bool):\n",
    "    # Get the dataset names (e.g., pos_zero_npair, pos_idval_npair, etc.)\n",
    "    dataset_names = df.columns[2:-1].unique()\n",
    "    dataset_names_parsed = [dataset_name_parser(ds_name) for ds_name in dataset_names]\n",
    "    # Get the model names (e.g., erm, irm, etc.)\n",
    "    model_names = df['model'].unique()\n",
    "    model_names_parsed = [MODEL_NAMES[model_name] for model_name in model_names]\n",
    "\n",
    "    # Variable to track if significant improvement was observed in AFR$_P$\n",
    "    significant_improvement_observed = False\n",
    "    \n",
    "    # Start building the LaTeX table\n",
    "    latex_code = \"\\\\begin{table}[H]\\n\\\\centering\\n\\\\resizebox{\\\\textwidth}{!}{%\\n\\\\begin{tabular}{l|cl|cl|cl|cl|cl|cl}\\n\"\n",
    "\n",
    "    # Header for shift values\n",
    "    # shift_text = lambda shift: f\"Test \\#{shift}\"\n",
    "    shift_text = lambda shift: f\"Test {shift}\"\n",
    "    latex_code += \"\\\\multirow{2}{*}{} & \" + \" & \".join(\n",
    "        [\n",
    "        f\"\\\\multicolumn{{2}}{{c|}}{{\\\\textbf{{{shift_text(shift)}}}}}\" if shift < 5 else f\"\\\\multicolumn{{2}}{{c}}{{\\\\textbf{{{shift_text(shift)}}}}}\"\n",
    "        for shift in range(6)\n",
    "    ]\n",
    "    ) + \" \\\\\\\\\\n\"\n",
    "\n",
    "    # Select the indexes of the best accuracies:    \n",
    "    list_max_acc, list_max_pa = [], []\n",
    "    for model in model_names:\n",
    "        accs_dataset = np.zeros((len(dataset_names), 6))\n",
    "        for idataset, dataset in enumerate(dataset_names):\n",
    "            for shift in range(6):\n",
    "                row = df[(df['shift'] == shift) & (df['model'] == model)]\n",
    "                if not row.empty:\n",
    "                    acc =  100.0*row[dataset][row['metric'] == 'acc'].values[0]\n",
    "                else:\n",
    "                    acc= 0.0\n",
    "                accs_dataset[idataset, shift] = acc\n",
    "        list_max_acc.append(np.argmax(accs_dataset, axis=0))\n",
    "    \n",
    "    \n",
    "    # Iterate over each model\n",
    "    for imodel, (model, model_parsed) in enumerate(zip(model_names, model_names_parsed)):\n",
    "        # Header for metrics (Acc., PA)\n",
    "        latex_code += f\"\\\\textbf{{{model_parsed}}} & \" + \" & \".join(\n",
    "            # [r\"\\textbf{Acc.} & \\textbf{PA}\" for _ in range(6)]\n",
    "            [r\"Acc. & $\\Delta$Acc.\" for _ in range(6)]\n",
    "        ) + \" \\\\\\\\\\n\"\n",
    "        latex_code += \"\\\\midrule\\n\"\n",
    "\n",
    "        # Iterate over each dataset\n",
    "        for idataset, (dataset, dataset_parsed) in enumerate(zip(dataset_names, dataset_names_parsed)):\n",
    "            latex_code += f\"{dataset_parsed}\"\n",
    "            # latex_code += f\"\\\\textbf{{{dataset_parsed}}}\"\n",
    "            for shift in range(6):\n",
    "                # Filter the DataFrame for the current dataset, model, and shift\n",
    "                row = df[(df['shift'] == shift) & (df['model'] == model)]\n",
    "                if not row.empty:\n",
    "                    # Extract the metric values for the current dataset, model, and shift\n",
    "                    acc = 100.0*row[dataset][row['metric'] == 'acc'].values[0]\n",
    "                    pa = 100.0*row[dataset][row['metric'] == 'pa'].values[0]\n",
    "\n",
    "                    # Replace 0.000 with a dash \"-\"\n",
    "                    # acc_str = f\"\\\\textbf{{{acc:.1f}}}\" if idataset == list_max_acc[imodel][shift] else f\"{acc:.1f}\"\n",
    "                    acc_str = f\"{acc:.1f}\"\n",
    "                    if float(f\"{pa:.1f}\") > 0:\n",
    "                        pa_str_in = f\"\\Plus {abs(pa):.1f}\"\n",
    "                        pa_str = f\"{{\\\\color{{tab:green}}  \\\\textbf{{{pa_str_in}}}}}\"\n",
    "                    elif float(f\"{pa:.1f}\") < 0:\n",
    "                        pa_str_in = f\"\\Minus {abs(pa):.1f}\"\n",
    "                        pa_str = f\"{{\\\\color{{tab:red}} \\\\textbf{{{pa_str_in}}}}}\"\n",
    "                    else:\n",
    "                        pa_str = r\"\\PlusMinus 0.01\" #\"0.0\"\n",
    "                    \n",
    "                    latex_code += f\" & {acc_str} & {pa_str}\"\n",
    "                else:\n",
    "                    latex_code += \" & - & -\"  # Placeholder if there's no data\n",
    "            latex_code += \" \\\\\\\\\\n\"\n",
    "\n",
    "\n",
    "        if imodel < len(model_names)-1:\n",
    "            latex_code += \"\\\\midrule\\n\\\\addlinespace\\n\\\\addlinespace\\n\"\n",
    "    \n",
    "    latex_code += \"\\\\bottomrule\\n\\\\end{tabular}%\\n}\\n\"\n",
    "\n",
    "    # Add caption with significant improvement information\n",
    "    caption_text = f\"REMOVEopt={optimizer}-lr={lr}-mf={main_factor}-npair={n_pair}REMOVE Test performance on increasingly shifted datasets for models selected during ERM and IRM procedures. Different validation datasets are used, and the selection capabilities of PA and validation accuracy are compared.\"\n",
    "    latex_code += f\"\\\\caption{{{caption_text}}}\\n\\\\label{{tab:label}}\\n\\\\end\" + \"{\" + \"table}\"\n",
    "    \n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = 'adam'\n",
    "lr = 0.0001\n",
    "main_factor = \"pos\"\n",
    "n_pair = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _get_table_of_results(\n",
    "        model_list = ['lisa_ppred=0.5'],\n",
    "        main_factor = main_factor,\n",
    "        n_pair = n_pair,\n",
    "        optimizer = optimizer, \n",
    "        lr = lr\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if `AFR_pred` improves the results, and write it in the caption:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afr = df.loc[df[\"metric\"] == \"afrp\"]\n",
    "df_afr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = generate_latex_table(df, optimizer=optimizer, lr=lr, main_factor=main_factor, n_pair=n_pair)\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EN MASSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "latex_code = \"\"\n",
    "for main_factor in ['hue']:\n",
    "        for n_pair in [False]:\n",
    "                for optimizer, lr in [('adam', 0.0001), ('adam', 0.0005)]:\n",
    "                        df = _get_table_of_results(\n",
    "                                model_list = ['lisa_ppred=0.5'],\n",
    "                                main_factor = main_factor,\n",
    "                                n_pair = n_pair,\n",
    "                                optimizer = optimizer, \n",
    "                                lr = lr\n",
    "                        )\n",
    "                        latex_code_table = generate_latex_table(df, optimizer=optimizer, lr=lr, main_factor=main_factor, n_pair=n_pair)\n",
    "                        latex_code += latex_code_table + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{l|cl|cl|cl|cl|cl|cl}\n",
      "\\multirow{2}{*}{} & \\multicolumn{2}{c|}{\\textbf{Test 0}} & \\multicolumn{2}{c|}{\\textbf{Test 1}} & \\multicolumn{2}{c|}{\\textbf{Test 2}} & \\multicolumn{2}{c|}{\\textbf{Test 3}} & \\multicolumn{2}{c|}{\\textbf{Test 4}} & \\multicolumn{2}{c}{\\textbf{Test 5}} \\\\\n",
      "\\textbf{{\\color{tab:green} \\textbf{LISA}}} & Acc. & $\\Delta$Acc. & Acc. & $\\Delta$Acc. & Acc. & $\\Delta$Acc. & Acc. & $\\Delta$Acc. & Acc. & $\\Delta$Acc. & Acc. & $\\Delta$Acc. \\\\\n",
      "\\midrule\n",
      "SD & 99.5 & {\\color{tab:green}  \\textbf{\\Plus 99.3}} & 78.9 & {\\color{tab:green}  \\textbf{\\Plus 73.4}} & 73.1 & {\\color{tab:green}  \\textbf{\\Plus 66.9}} & 71.1 & {\\color{tab:green}  \\textbf{\\Plus 66.7}} & 69.9 & {\\color{tab:green}  \\textbf{\\Plus 68.3}} & 29.7 & {\\color{tab:green}  \\textbf{\\Plus 41.0}} \\\\\n",
      "ID & 99.5 & {\\color{tab:green}  \\textbf{\\Plus 99.4}} & 83.0 & {\\color{tab:green}  \\textbf{\\Plus 81.0}} & 53.3 & {\\color{tab:green}  \\textbf{\\Plus 86.1}} & 67.9 & {\\color{tab:green}  \\textbf{\\Plus 69.1}} & 56.5 & {\\color{tab:green}  \\textbf{\\Plus 61.8}} & 33.9 & {\\color{tab:green}  \\textbf{\\Plus 42.1}} \\\\\n",
      "1F-MD & 99.3 & {\\color{tab:green}  \\textbf{\\Plus 99.3}} & 79.3 & {\\color{tab:green}  \\textbf{\\Plus 79.3}} & 63.8 & {\\color{tab:green}  \\textbf{\\Plus 63.8}} & 63.3 & {\\color{tab:green}  \\textbf{\\Plus 63.3}} & 63.9 & {\\color{tab:green}  \\textbf{\\Plus 63.9}} & 27.9 & {\\color{tab:green}  \\textbf{\\Plus 27.9}} \\\\\n",
      "5F-MD & 99.2 & {\\color{tab:green}  \\textbf{\\Plus 99.2}} & 78.5 & {\\color{tab:green}  \\textbf{\\Plus 78.5}} & 80.2 & {\\color{tab:green}  \\textbf{\\Plus 80.2}} & 66.7 & {\\color{tab:green}  \\textbf{\\Plus 66.7}} & 63.6 & {\\color{tab:green}  \\textbf{\\Plus 63.6}} & 42.9 & {\\color{tab:green}  \\textbf{\\Plus 42.9}} \\\\\n",
      "OOD & 99.4 & {\\color{tab:green}  \\textbf{\\Plus 99.3}} & 81.0 & {\\color{tab:green}  \\textbf{\\Plus 70.7}} & 86.1 & {\\color{tab:green}  \\textbf{\\Plus 80.2}} & 69.1 & {\\color{tab:green}  \\textbf{\\Plus 75.9}} & 61.8 & {\\color{tab:green}  \\textbf{\\Plus 72.4}} & 42.1 & {\\color{tab:green}  \\textbf{\\Plus 36.8}} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}%\n",
      "}\n",
      "\\caption{REMOVEopt=adam-lr=0.0001-mf=hue-npair=FalseREMOVE Test performance on increasingly shifted datasets for models selected during ERM and IRM procedures. Different validation datasets are used, and the selection capabilities of PA and validation accuracy are compared.}\n",
      "\\label{tab:label}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{l|cl|cl|cl|cl|cl|cl}\n",
      "\\multirow{2}{*}{} & \\multicolumn{2}{c|}{\\textbf{Test 0}} & \\multicolumn{2}{c|}{\\textbf{Test 1}} & \\multicolumn{2}{c|}{\\textbf{Test 2}} & \\multicolumn{2}{c|}{\\textbf{Test 3}} & \\multicolumn{2}{c|}{\\textbf{Test 4}} & \\multicolumn{2}{c}{\\textbf{Test 5}} \\\\\n",
      "\\textbf{{\\color{tab:green} \\textbf{LISA}}} & Acc. & $\\Delta$Acc. & Acc. & $\\Delta$Acc. & Acc. & $\\Delta$Acc. & Acc. & $\\Delta$Acc. & Acc. & $\\Delta$Acc. & Acc. & $\\Delta$Acc. \\\\\n",
      "\\midrule\n",
      "SD & 99.4 & {\\color{tab:green}  \\textbf{\\Plus 99.3}} & 87.7 & {\\color{tab:green}  \\textbf{\\Plus 88.0}} & 63.8 & {\\color{tab:green}  \\textbf{\\Plus 62.6}} & 79.3 & {\\color{tab:green}  \\textbf{\\Plus 74.9}} & 74.8 & {\\color{tab:green}  \\textbf{\\Plus 71.1}} & 42.3 & {\\color{tab:green}  \\textbf{\\Plus 38.7}} \\\\\n",
      "ID & 99.4 & {\\color{tab:green}  \\textbf{\\Plus 99.4}} & 87.7 & {\\color{tab:green}  \\textbf{\\Plus 87.8}} & 63.8 & {\\color{tab:green}  \\textbf{\\Plus 55.6}} & 79.3 & {\\color{tab:green}  \\textbf{\\Plus 72.5}} & 74.8 & {\\color{tab:green}  \\textbf{\\Plus 70.4}} & 42.3 & {\\color{tab:green}  \\textbf{\\Plus 39.5}} \\\\\n",
      "1F-MD & 99.5 & {\\color{tab:green}  \\textbf{\\Plus 99.3}} & 88.8 & {\\color{tab:green}  \\textbf{\\Plus 91.7}} & 54.4 & {\\color{tab:green}  \\textbf{\\Plus 42.3}} & 76.8 & {\\color{tab:green}  \\textbf{\\Plus 61.9}} & 71.5 & {\\color{tab:green}  \\textbf{\\Plus 56.2}} & 36.4 & {\\color{tab:green}  \\textbf{\\Plus 28.9}} \\\\\n",
      "5F-MD & 99.3 & {\\color{tab:green}  \\textbf{\\Plus 99.3}} & 76.1 & {\\color{tab:green}  \\textbf{\\Plus 76.1}} & 70.2 & {\\color{tab:green}  \\textbf{\\Plus 70.2}} & 71.4 & {\\color{tab:green}  \\textbf{\\Plus 71.4}} & 70.6 & {\\color{tab:green}  \\textbf{\\Plus 70.6}} & 48.6 & {\\color{tab:green}  \\textbf{\\Plus 48.6}} \\\\\n",
      "OOD & 99.3 & {\\color{tab:green}  \\textbf{\\Plus 99.3}} & 91.8 & {\\color{tab:green}  \\textbf{\\Plus 91.8}} & 59.0 & {\\color{tab:green}  \\textbf{\\Plus 59.0}} & 77.6 & {\\color{tab:green}  \\textbf{\\Plus 77.6}} & 73.8 & {\\color{tab:green}  \\textbf{\\Plus 73.8}} & 34.4 & {\\color{tab:green}  \\textbf{\\Plus 34.4}} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}%\n",
      "}\n",
      "\\caption{REMOVEopt=adam-lr=0.0005-mf=hue-npair=FalseREMOVE Test performance on increasingly shifted datasets for models selected during ERM and IRM procedures. Different validation datasets are used, and the selection capabilities of PA and validation accuracy are compared.}\n",
      "\\label{tab:label}\n",
      "\\end{table}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LATEX TABLE APPENDIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(df, optimizer: str, lr: float, main_factor: str, n_pair: bool):\n",
    "    # Get the dataset names (e.g., pos_zero_npair, pos_idval_npair, etc.)\n",
    "    dataset_names = df.columns[2:-1].unique()\n",
    "    dataset_names_parsed = [dataset_name_parser(ds_name) for ds_name in dataset_names]\n",
    "    # Get the model names (e.g., erm, irm, etc.)\n",
    "    model_names = df['model'].unique()\n",
    "    model_names_parsed = [MODEL_NAMES[model_name] for model_name in model_names]\n",
    "\n",
    "    # Variable to track if significant improvement was observed in AFR$_P$\n",
    "    significant_improvement_observed = False\n",
    "\n",
    "    eps = 1e-4\n",
    "    \n",
    "    # Start building the LaTeX table\n",
    "    latex_code = \"\\\\begin{table}[H]\\n\\\\centering\\n\\\\setlength{\\\\tabcolsep}{2.5pt}\\n\\\\resizebox{\\\\textwidth}{!}{%\\n\\\\begin{tabular}{l|ccc|ccc|ccc|ccc|ccc|ccc}\\n\"\n",
    "\n",
    "    # Header for shift values\n",
    "    # shift_text = lambda shift: f\"Test \\#{shift}\"\n",
    "    shift_text = lambda shift: f\"Acc. Test {shift}\"\n",
    "    latex_code += \"\\\\multirow{3}{*}{} & \" + \" & \".join(\n",
    "        [\n",
    "        f\"\\\\multicolumn{{3}}{{c|}}{{\\\\textbf{{{shift_text(shift)}}}}}\" if shift < 5 else f\"\\\\multicolumn{{3}}{{c}}{{\\\\textbf{{{shift_text(shift)}}}}}\"\n",
    "        for shift in range(6)\n",
    "    ]\n",
    "    ) + \" \\\\\\\\\\n\"    \n",
    "    \n",
    "    # Iterate over each model\n",
    "    for imodel, (model, model_parsed) in enumerate(zip(model_names, model_names_parsed)):\n",
    "        # Header for metrics (Acc., PA)\n",
    "        latex_code += f\"\\\\textbf{{{model_parsed}}} & \" + \" & \".join(\n",
    "            # [r\"\\textbf{Acc.} & \\textbf{PA}\" for _ in range(6)]\n",
    "            [r\"Acc. & AFR$_\\text{P}$ & PA\" for _ in range(6)]\n",
    "        ) + \" \\\\\\\\\\n\"\n",
    "        latex_code += \"\\\\midrule\\n\"\n",
    "\n",
    "        # Iterate over each dataset\n",
    "        for idataset, (dataset, dataset_parsed) in enumerate(zip(dataset_names, dataset_names_parsed)):\n",
    "            latex_code += f\"{dataset_parsed}\"\n",
    "            # latex_code += f\"\\\\textbf{{{dataset_parsed}}}\"\n",
    "            for shift in range(6):\n",
    "                # Filter the DataFrame for the current dataset, model, and shift\n",
    "                row = df[(df['shift'] == shift) & (df['model'] == model)]\n",
    "                if not row.empty:\n",
    "                    # Extract the metric values for the current dataset, model, and shift\n",
    "                    acc = 100.0*row[dataset][row['metric'] == 'acc'].values[0]\n",
    "                    pa = 100.0*row[dataset][row['metric'] == 'pa'].values[0]\n",
    "                    afr = 100.0*row[dataset][row['metric'] == 'afrp'].values[0]\n",
    "\n",
    "                    acc_str, pa_str, afr_str = f\"{acc:.1f}\", f\"{pa:.1f}\", f\"{afr:.1f}\"\n",
    "                    str_metrics = [acc_str, afr_str, pa_str]\n",
    "                    float_metrics = [float(val) for val in str_metrics]\n",
    "                    max_val = max(float_metrics)\n",
    "                    if abs(float_metrics[2] - max_val) < eps:\n",
    "                        pa_str = f\"{{\\\\textbf{{{pa_str}}}}}\"\n",
    "                    elif abs(float_metrics[0] - max_val) < eps:\n",
    "                        acc_str = f\"{{\\\\textbf{{{acc_str}}}}}\"\n",
    "                    else:\n",
    "                        afr_str = f\"{{\\\\textbf{{{afr_str}}}}}\"\n",
    "\n",
    "                    \n",
    "                    latex_code += f\" & {acc_str} & {afr_str} & {pa_str}\"\n",
    "                else:\n",
    "                    latex_code += \" & - & - & -\"  # Placeholder if there's no data\n",
    "            latex_code += \" \\\\\\\\\\n\"\n",
    "\n",
    "\n",
    "        if imodel < len(model_names)-1:\n",
    "            latex_code += \"\\\\midrule\\n\\\\addlinespace\\n\\\\addlinespace\\n\"\n",
    "    \n",
    "    latex_code += \"\\\\bottomrule\\n\\\\end{tabular}%\\n}\\n\"\n",
    "\n",
    "    # Add caption with significant improvement information\n",
    "    caption_text = f\"REMOVEopt={optimizer}-lr={lr}-mf={main_factor}-npair={n_pair}APPENDIX.\"\n",
    "    latex_code += f\"\\\\caption{{{caption_text}}}\\n\\\\label{{tab:label}}\\n\\\\end\" + \"{\" + \"table}\"\n",
    "    \n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "latex_code = \"\"\n",
    "for main_factor in ['hue']:\n",
    "        for n_pair in [True]:\n",
    "                for optimizer, lr in [('adam', 0.0001), ('adam', 0.0005)]: # ('adam', 0.0001), ('adam', 0.0005)\n",
    "                        df = _get_table_of_results(\n",
    "                                model_list = ['lisa_ppred=0.5'],\n",
    "                                main_factor = main_factor,\n",
    "                                n_pair = n_pair,\n",
    "                                optimizer = optimizer, \n",
    "                                lr = lr\n",
    "                        )\n",
    "                        latex_code_table = generate_latex_table(df, optimizer=optimizer, lr=lr, main_factor=main_factor, n_pair=n_pair)\n",
    "                        latex_code += latex_code_table + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\setlength{\\tabcolsep}{2.5pt}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{l|ccc|ccc|ccc|ccc|ccc|ccc}\n",
      "\\multirow{3}{*}{} & \\multicolumn{3}{c|}{\\textbf{Acc. Test 0}} & \\multicolumn{3}{c|}{\\textbf{Acc. Test 1}} & \\multicolumn{3}{c|}{\\textbf{Acc. Test 2}} & \\multicolumn{3}{c|}{\\textbf{Acc. Test 3}} & \\multicolumn{3}{c|}{\\textbf{Acc. Test 4}} & \\multicolumn{3}{c}{\\textbf{Acc. Test 5}} \\\\\n",
      "\\textbf{{\\color{tab:green} \\textbf{LISA}}} & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA \\\\\n",
      "\\midrule\n",
      "SD & 99.3 & 99.3 & {\\textbf{99.4}} & {\\textbf{88.4}} & 88.4 & 83.1 & 53.9 & 53.9 & {\\textbf{78.5}} & 57.9 & 57.9 & {\\textbf{80.5}} & 63.1 & 63.1 & {\\textbf{77.0}} & {\\textbf{38.8}} & 38.8 & 35.4 \\\\\n",
      "ID & 99.3 & 99.3 & {\\textbf{99.4}} & {\\textbf{88.4}} & 88.4 & 83.1 & 53.9 & 53.9 & {\\textbf{78.5}} & 57.9 & 57.9 & {\\textbf{80.5}} & 63.1 & 63.1 & {\\textbf{77.0}} & {\\textbf{38.8}} & 38.8 & 35.4 \\\\\n",
      "1F-MD & 99.3 & 99.3 & {\\textbf{99.3}} & 79.3 & 79.3 & {\\textbf{79.3}} & 63.8 & 63.8 & {\\textbf{63.8}} & 63.3 & 63.3 & {\\textbf{63.3}} & 63.9 & 63.9 & {\\textbf{63.9}} & 27.9 & 27.9 & {\\textbf{27.9}} \\\\\n",
      "5F-MD & 99.2 & 99.2 & {\\textbf{99.3}} & 78.5 & 78.5 & {\\textbf{88.4}} & {\\textbf{80.2}} & 80.2 & 53.9 & {\\textbf{66.7}} & 66.7 & 57.9 & {\\textbf{63.6}} & 63.6 & 63.1 & {\\textbf{42.9}} & 42.9 & 38.8 \\\\\n",
      "OOD & 99.4 & 99.4 & {\\textbf{99.4}} & 81.0 & 81.0 & {\\textbf{81.0}} & 86.1 & 86.1 & {\\textbf{86.1}} & 69.1 & 69.1 & {\\textbf{69.1}} & 61.8 & 61.8 & {\\textbf{61.8}} & 42.1 & 42.1 & {\\textbf{42.1}} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}%\n",
      "}\n",
      "\\caption{REMOVEopt=adam-lr=0.0001-mf=hue-npair=TrueAPPENDIX.}\n",
      "\\label{tab:label}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\setlength{\\tabcolsep}{2.5pt}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{l|ccc|ccc|ccc|ccc|ccc|ccc}\n",
      "\\multirow{3}{*}{} & \\multicolumn{3}{c|}{\\textbf{Acc. Test 0}} & \\multicolumn{3}{c|}{\\textbf{Acc. Test 1}} & \\multicolumn{3}{c|}{\\textbf{Acc. Test 2}} & \\multicolumn{3}{c|}{\\textbf{Acc. Test 3}} & \\multicolumn{3}{c|}{\\textbf{Acc. Test 4}} & \\multicolumn{3}{c}{\\textbf{Acc. Test 5}} \\\\\n",
      "\\textbf{{\\color{tab:green} \\textbf{LISA}}} & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA & Acc. & AFR$_\\text{P}$ & PA \\\\\n",
      "\\midrule\n",
      "SD & 99.5 & 99.5 & {\\textbf{99.5}} & 88.8 & 88.8 & {\\textbf{88.8}} & 54.4 & 54.4 & {\\textbf{54.4}} & 76.8 & 76.8 & {\\textbf{76.8}} & 71.5 & 71.5 & {\\textbf{71.5}} & 36.4 & 36.4 & {\\textbf{36.4}} \\\\\n",
      "ID & 99.5 & 99.5 & {\\textbf{99.5}} & 59.2 & 59.2 & {\\textbf{88.8}} & {\\textbf{62.5}} & 62.5 & 54.4 & 71.7 & 71.7 & {\\textbf{76.8}} & 70.9 & 70.9 & {\\textbf{71.5}} & 35.2 & 35.2 & {\\textbf{36.4}} \\\\\n",
      "1F-MD & 99.5 & 99.5 & {\\textbf{99.5}} & 88.8 & 88.8 & {\\textbf{88.8}} & 54.4 & 54.4 & {\\textbf{54.4}} & 76.8 & 76.8 & {\\textbf{76.8}} & 71.5 & 71.5 & {\\textbf{71.5}} & 36.4 & 36.4 & {\\textbf{36.4}} \\\\\n",
      "5F-MD & 99.2 & 99.2 & {\\textbf{99.4}} & {\\textbf{86.6}} & 86.6 & 85.1 & 71.1 & 71.1 & {\\textbf{74.8}} & 77.3 & 77.3 & {\\textbf{83.7}} & 73.7 & 73.7 & {\\textbf{81.9}} & {\\textbf{49.4}} & 49.4 & 48.6 \\\\\n",
      "OOD & {\\textbf{99.3}} & 99.2 & 99.2 & 91.8 & {\\textbf{95.8}} & 84.4 & 59.0 & 63.0 & {\\textbf{83.0}} & 77.6 & 79.0 & {\\textbf{88.0}} & 73.8 & 73.6 & {\\textbf{84.8}} & 34.4 & 40.4 & {\\textbf{47.3}} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}%\n",
      "}\n",
      "\\caption{REMOVEopt=adam-lr=0.0005-mf=hue-npair=TrueAPPENDIX.}\n",
      "\\label{tab:label}\n",
      "\\end{table}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLES OF SURPLUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_pa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
