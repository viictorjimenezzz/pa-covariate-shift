{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pyrootutils\n",
    "\n",
    "notebook_path = Path(os.path.abspath(\"\"))\n",
    "pyrootutils.setup_root(notebook_path, indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "DIRNAME = r\"/cluster/home/vjimenez/adv_pa_new/results/dg/datashift\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot.dg import *\n",
    "from src.plot.dg._retrieve import *\n",
    "from src.plot.dg._plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_names_shift(run_string):\n",
    "    \"\"\"(model, optimizer, gpu, ppred)\"\"\"\n",
    "    if run_string[:3] == \"sgd\":\n",
    "        optimizer = \"sgd\"\n",
    "        run_string = run_string[3:]\n",
    "    else:\n",
    "        optimizer = \"adam\"\n",
    "\n",
    "    split_run = run_string.split(\"_\")\n",
    "    if len(split_run) == 1: # erm, irm\n",
    "        return (split_run[0], optimizer, \"ddp\", None)\n",
    "    elif len(split_run) == 2:\n",
    "        if split_run[1].isdigit(): # lisa_ppred\n",
    "            return (split_run[0], optimizer, \"ddp\", split_run[1])\n",
    "        else: # erm_gpu, irm_gpu\n",
    "            return (split_run[0], optimizer, \"gpu\", None)\n",
    "        \n",
    "    else: # split_run == 3, lisa_gpu_ppred\n",
    "        return (split_run[0],optimizer, \"gpu\", split_run[2])\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "def plot_variable_vs_run(\n",
    "        data: dict,\n",
    "        dataset_list: list,\n",
    "        run_names: list,\n",
    "        metrics: list,\n",
    "        hue_attribute: str,\n",
    "        hue_dict: dict,\n",
    "        ylabel: str,\n",
    "        legend_labels: list,\n",
    "        title: str,\n",
    "        savedir: str,\n",
    "        yscale: Optional[bool] = \"symlog\",\n",
    "        legend: Optional[bool] = True,\n",
    "        legend_loc: Optional[str] = \"best\",\n",
    "        save: Optional[bool] = False,\n",
    "        version_appendix: Optional[str] = \"\"\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            data (dict): Dictionary with all the data for the desired runs.\n",
    "            metric (str): Name of the metric to plot.\n",
    "            selection_metric (str): Name of the metric that guides the selection of the `metric` values to plot.\n",
    "            selection_criterion (str): Criterion of the `selection_metric`. Accepts \"min\", \"max\", \"first\" and \"last\".\n",
    "            selection_environment (Optional[int]): Environment to implement the selection criterion. If None, it will be implemented\n",
    "                for each environment separately.\n",
    "    \"\"\"\n",
    "    # Number of runs:\n",
    "    num_runs = len(run_names)\n",
    "    run_attributes = [extract_names_shift(name) for name in run_names] #(model, opt, lr)\n",
    "\n",
    "    name_datasets = set(dataset_list)\n",
    "    num_datasets = len(name_datasets)\n",
    "\n",
    "    # Get the font\n",
    "    fontname = \"DejaVu Serif\"\n",
    "    _ = fm.findfont(fm.FontProperties(family=fontname))\n",
    "\n",
    "    # Subset of the dictionary:\n",
    "    dict_to_iter = {\n",
    "        \"dataset\": list(name_datasets)*num_runs,\n",
    "        \"model\": [attrs[0] for attrs in run_attributes]*num_datasets,\n",
    "        \"trainer\": [attrs[1] for attrs in run_attributes]*num_datasets,\n",
    "        \"optimizer\": [attrs[2] for attrs in run_attributes]*num_datasets,\n",
    "        \"ppred\": [attrs[3] for attrs in run_attributes]*num_datasets,\n",
    "    }    \n",
    "\n",
    "    df_list = []\n",
    "    for irun in range(num_runs*num_datasets):\n",
    "        dict_to_plot = {\n",
    "            \"epochs\": np.arange(1, 101)\n",
    "        }\n",
    "        dict_to_plot.update({\n",
    "            key: np.full(100, values[irun])\n",
    "            for key, values in dict_to_iter.items()\n",
    "        })\n",
    "        dict_to_plot.update({\n",
    "            metric: data[metric][irun]\n",
    "            for metric in metrics\n",
    "        })\n",
    "        try:\n",
    "            df = pd.DataFrame(dict_to_plot)\n",
    "        except:\n",
    "            import ipdb; ipdb.set_trace()\n",
    "        df_list.append(df)\n",
    "    \n",
    "    level_set = pd.concat(df_list)\n",
    "    \n",
    "    # Create a line plot\n",
    "    plt.close('all')\n",
    "    _, ax = plt.subplots(figsize=(2 * 3.861, 2 * 2.7291))\n",
    "    sns.set(font_scale=1.9)\n",
    "    plt.rcParams[\"font.family\"] = \"serif\"\n",
    "    plt.rcParams[\"font.serif\"] = fontname\n",
    "    sns.set_style(\"ticks\")\n",
    "\n",
    "\n",
    "    for metric in metrics:\n",
    "        sns.lineplot(\n",
    "            data=level_set,\n",
    "            ax=ax,\n",
    "            x=\"epochs\",\n",
    "            y=metric,\n",
    "            hue=hue_attribute,\n",
    "            style=hue_attribute,\n",
    "            palette=hue_dict,\n",
    "            dashes=[(2,2)] if metric == metrics[0] else False, #dash_styles.get(metric, False),\n",
    "            marker=None,\n",
    "            linewidth=3,\n",
    "            legend=legend\n",
    "        )\n",
    "\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "    ax.set_xticks([1] + [i for i in range(10,101,10)])\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", direction=\"in\")\n",
    "    xticks_font = fm.FontProperties(family=fontname)\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_fontproperties(xticks_font)\n",
    "\n",
    "    ax.grid(linestyle=\"--\")\n",
    "\n",
    "    # ax.set_ylim(min(level_set[metric])*2, 0.5)\n",
    "        \n",
    "    # posdiff = -(10**np.log10(abs(max(level_set[metric]))))/2\n",
    "    # ax.set_ylim(min(level_set[metric])*2, posdiff)\n",
    "    ax.set_xlabel(\"Epochs\", fontname=fontname)\n",
    "    # r\"$10^{-4} \\times $ PA\"\n",
    "    ax.set_ylabel(ylabel, fontname=fontname)\n",
    "    ax.set_yscale(yscale) \n",
    "    \n",
    "    # Legend\n",
    "    if legend == True:\n",
    "        handles, _ = ax.get_legend_handles_labels()\n",
    "\n",
    "        # FOR TRAIN AND VAL METRICS:\n",
    "        legend_labels = [\"Training\", \"Validation\"] + legend_labels\n",
    "        \n",
    "        for handle in handles[:2]:\n",
    "            handle.set_color(\"black\")\n",
    "        handles[1].set_linestyle(\"-\")\n",
    "        \n",
    "            \n",
    "        legend_properties = {\n",
    "            \"family\": fontname,\n",
    "            'size': 18,\n",
    "        }  \n",
    "        ax.legend(\n",
    "            handles,\n",
    "            legend_labels,\n",
    "            loc=legend_loc,\n",
    "            # loc=\"lower left\",\n",
    "            # fontsize=12,\n",
    "            handlelength=0.5,\n",
    "            prop=legend_properties\n",
    "        )\n",
    "\n",
    "    ax.set_title(title, fontname=fontname)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(savedir)\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run: 100%|██████████| 4/4 [00:01<00:00,  2.87it/s]\n"
     ]
    }
   ],
   "source": [
    "run_names = [f\"erm\", f\"irm\", \"lisa_00\", \"lisa_10\"]\n",
    "ds_list = [\"CGO_2_hue\"]\n",
    "data_dict = get_multiple_dict(\n",
    "    ds_list,\n",
    "    run_names,\n",
    "    datashift=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_1805482/4087828590.py\u001b[0m(66)\u001b[0;36mplot_variable_vs_run\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     65 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 66 \u001b[0;31m        \u001b[0mdf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
      "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
      "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
      "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
      "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
      "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "        92,  93,  94,  95,  96,  97,  98,  99, 100]), 'dataset': array(['CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue',\n",
      "       'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue', 'CGO_2_hue'],\n",
      "      dtype='<U9'), 'model': array(['lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa',\n",
      "       'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa',\n",
      "       'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa',\n",
      "       'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa',\n",
      "       'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa',\n",
      "       'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa',\n",
      "       'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa',\n",
      "       'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa',\n",
      "       'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa',\n",
      "       'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa',\n",
      "       'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa',\n",
      "       'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa', 'lisa',\n",
      "       'lisa', 'lisa', 'lisa', 'lisa'], dtype='<U4'), 'trainer': array(['adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
      "       'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
      "       'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
      "       'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
      "       'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
      "       'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
      "       'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
      "       'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
      "       'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
      "       'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
      "       'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
      "       'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
      "       'adam', 'adam', 'adam', 'adam'], dtype='<U4'), 'optimizer': array(['ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp',\n",
      "       'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp',\n",
      "       'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp',\n",
      "       'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp',\n",
      "       'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp',\n",
      "       'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp',\n",
      "       'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp',\n",
      "       'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp',\n",
      "       'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp',\n",
      "       'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp',\n",
      "       'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp', 'ddp',\n",
      "       'ddp'], dtype='<U3'), 'ppred': array(['00', '00', '00', '00', '00', '00', '00', '00', '00', '00', '00',\n",
      "       '00', '00', '00', '00', '00', '00', '00', '00', '00', '00', '00',\n",
      "       '00', '00', '00', '00', '00', '00', '00', '00', '00', '00', '00',\n",
      "       '00', '00', '00', '00', '00', '00', '00', '00', '00', '00', '00',\n",
      "       '00', '00', '00', '00', '00', '00', '00', '00', '00', '00', '00',\n",
      "       '00', '00', '00', '00', '00', '00', '00', '00', '00', '00', '00',\n",
      "       '00', '00', '00', '00', '00', '00', '00', '00', '00', '00', '00',\n",
      "       '00', '00', '00', '00', '00', '00', '00', '00', '00', '00', '00',\n",
      "       '00', '00', '00', '00', '00', '00', '00', '00', '00', '00', '00',\n",
      "       '00'], dtype='<U2'), 'train/acc': array([0.86384511, 0.92993987, 0.93829328, 0.94492483]), 'val/acc': array([0.98848927, 0.99626958, 0.99404633, 0.99667907])}\n",
      "\n",
      "*** SyntaxError: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "trainval_metrics = [\"acc\", \"loss\", \"specificity\", \"sensitivity\", \"precision\"]\n",
    "for met in trainval_metrics: \n",
    "    legend = False\n",
    "    if met == \"loss\":\n",
    "        legend = False\n",
    "\n",
    "    mettitle = met.capitalize()\n",
    "    if met == \"acc\":\n",
    "        mettitle = \"Accuracy\"\n",
    "\n",
    "    plot_variable_vs_run(\n",
    "        data=data_dict,\n",
    "        run_names=run_names,\n",
    "        dataset_list = ds_list,\n",
    "        metrics=[f\"train/{met}\", f\"val/{met}\"],\n",
    "        hue_attribute=\"model\",\n",
    "        hue_dict={\n",
    "            \"erm\": \"tab:blue\",\n",
    "            \"irm\": \"tab:orange\",\n",
    "            \"lisa\": \"tab:green\"\n",
    "        },\n",
    "        title=f\"{mettitle}\",\n",
    "        legend_labels=[\"ERM\", \"IRM\", \"LISA\"],\n",
    "        ylabel=\"\",\n",
    "        # title=f\"{mod.upper()}\",\n",
    "        savedir=os.path.join(DIRNAME, rf\"{ds_list[0]}/adam_mod_{met}.png\"),\n",
    "        yscale=\"linear\",\n",
    "        legend=legend,\n",
    "        save=True,\n",
    "        version_appendix=\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_pa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
