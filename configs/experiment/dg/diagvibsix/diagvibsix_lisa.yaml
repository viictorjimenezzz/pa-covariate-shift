# @package _global_

defaults:
  - /experiment/dg/diagvibsix/diagvibsix.yaml
  - /model/dg@model: lisa.yaml

model:
  ppred: ???
  mix_alpha: 2.0
  mixup_strategy: mixup
  
  optimizer:
    _target_: torch.optim.Adam
    lr: 0.002

  net:
    pretrained: false
    net: resnet18
    n_classes: ${data.n_classes}

  scheduler:
    monitor: val/loss
    interval: epoch
    frequency: 1
  
    scheduler:
      _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
      _partial_: true
      mode: min
      factor: 0.1
      patience: 10

tags: 
  - "dg"
  - "diagvibsix"
  - "${diagvib_folder: ${data.dataset_dir}}"
  - "lisa"
  - "${model.net.net}"
  - "${classname: ${model.optimizer._target_}}"

