# @package _global_

defaults:
  # Data source
  - /data/dg@datamodules.main: diagvib_multienv.yaml
  - /data/dg@datamodules.pa: diagvib_PA.yaml
  - /data/dg@datamodules.pa_logits: diagvib_PA.yaml  # !! needs classifier

  # Trainers
  - /trainer@trainer.cpu: cpu.yaml
  - /trainer@trainer.ddp: ddp.yaml

  # Classifier for PA_logits. I write confis here to be easily accessible
  - /model/dg/net@datamodules.pa_logits.classifier
exp_name: lisa_rebuttalL
shift_ratio: 1.0

expected_results:
  main:
    corresponding_labels: False # whether main dataset has corresponding labels

trainer:
  cpu:
    max_epochs: 10
  ddp:
    max_epochs: 10

datamodules:
  data_name: diagvib
  main:
    envs_index: [0,1]
    envs_name: singlevar
    datasets_dir: ${paths.data_dir}/dg/dg_datasets/test_data_pipeline/
    disjoint_envs: True
    train_val_sequential: True

    collate_fn:
      _target_: hydra.utils.get_method
      path: src.data.components.collate_functions.MultiEnv_collate_fn
    batch_size: 64 # Same as the one that was passed to the model.
    num_workers: 2
    pin_memory: True
    

  pa:
    _target_: src.data.diagvib_datamodules.DiagVibDataModulePA
    shift_ratio: ${ddp.shift_ratio}

    envs_index: ${ddp.datamodules.main.envs_index}
    envs_name: train_${ddp.datamodules.main.envs_name} # remember it is necessary to write 'train', 'test' or 'val'
    datasets_dir: ${ddp.datamodules.main.datasets_dir}
    disjoint_envs: ${ddp.datamodules.main.disjoint_envs}
    train_val_sequential: ${ddp.datamodules.main.train_val_sequential}

    collate_fn: ${ddp.datamodules.main.collate_fn}
    batch_size: ${ddp.datamodules.main.batch_size}
    num_workers: ${ddp.datamodules.main.num_workers}
    pin_memory: ${ddp.datamodules.main.pin_memory}


  pa_logits:
    _target_: src.data.diagvib_datamodules.DiagVibDataModulePAlogits
    shift_ratio: ${ddp.shift_ratio}
    classifier:
      _target_: src.models.components.dg_backbone.get_lm_model
      exp_name: ${ddp.exp_name}
      log_dir: ${paths.log_dir}

    envs_index: ${ddp.datamodules.main.envs_index}
    envs_name: train_${ddp.datamodules.main.envs_name} # remember it is necessary to write 'train', 'test' or 'val'
    datasets_dir: ${ddp.datamodules.main.datasets_dir}
    disjoint_envs: ${ddp.datamodules.main.disjoint_envs}
    train_val_sequential: ${ddp.datamodules.main.train_val_sequential}

    collate_fn: ${ddp.datamodules.main.collate_fn}
    batch_size: ${ddp.datamodules.main.batch_size}
    num_workers: ${ddp.datamodules.main.num_workers}
    pin_memory: ${ddp.datamodules.main.pin_memory}
  