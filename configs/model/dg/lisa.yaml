# Not necessary, dont copy when cluster is available again
defaults:
  - net.yaml

_target_: src.models.lisa.LISA

mixup_strategy: "mixup"
ppred: 1.0 # probability of LISA-L
mix_alpha: 0.4 # mixup weight

loss:
  _target_: torch.nn.CrossEntropyLoss

n_classes: ${model.net.n_classes}

optimizer: ???
  # _target_: torch.optim.Adam
  # _partial_: true
  # lr: 0.001
  # weight_decay: 0.0

scheduler: ???
  # monitor: val/loss
  # interval: epoch
  # frequency: 1 # ${trainer.check_val_every_n_epoch}

  # scheduler:
  #   _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  #   _partial_: true
  #   mode: min
  #   factor: 0.1
  #   patience: 10